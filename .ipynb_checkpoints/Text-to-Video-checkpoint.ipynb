{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb55704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub version: 0.34.4\n",
      "diffusers version: 0.34.0\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "import diffusers\n",
    "\n",
    "print(\"huggingface_hub version:\", huggingface_hub.__version__)\n",
    "print(\"diffusers version:\", diffusers.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3993c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 MODE: fast — Generating image from text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7ca4b8266841a18b6c8a336f04b58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc582183bc0a4907b4cff09b713c1ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image saved to generated_image.png\n",
      "🎥 Generating video from image...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac9d9f4ecab403892bfd9417261958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad27458c22494c1384f4754fa00a51d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, StableVideoDiffusionPipeline\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from IPython.display import Video, display\n",
    "import time\n",
    "\n",
    "# ------------------------\n",
    "# MODE TOGGLE (\"fast\" or \"final\")\n",
    "# ------------------------\n",
    "MODE = \"fast\"   # Change to \"final\" for high-quality output\n",
    "\n",
    "# ------------------------\n",
    "# SETTINGS BASED ON MODE\n",
    "# ------------------------\n",
    "if MODE == \"fast\":\n",
    "    num_frames = 4\n",
    "    num_inference_steps_img = 20\n",
    "    num_inference_steps_vid = 15\n",
    "    height = 256\n",
    "    width = 256\n",
    "elif MODE == \"final\":\n",
    "    num_frames = 8\n",
    "    num_inference_steps_img = 50\n",
    "    num_inference_steps_vid = 40\n",
    "    height = 512\n",
    "    width = 512\n",
    "else:\n",
    "    raise ValueError(\"MODE must be 'fast' or 'final'.\")\n",
    "\n",
    "# ------------------------\n",
    "# FILE PATHS & PROMPT\n",
    "# ------------------------\n",
    "prompt = \"A calm forest with soft sunlight filtering through the trees\"\n",
    "image_path = \"generated_image.png\"\n",
    "video_path = \"generated_video.mp4\"\n",
    "\n",
    "# ------------------------\n",
    "# STEP 1: TEXT → IMAGE\n",
    "# ------------------------\n",
    "print(f\"🎨 MODE: {MODE} — Generating image from text...\")\n",
    "start_time = time.time()\n",
    "pipe_img = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float32\n",
    ").to(\"cpu\")\n",
    "\n",
    "image = pipe_img(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=num_inference_steps_img,\n",
    "    height=height,\n",
    "    width=width\n",
    ").images[0]\n",
    "\n",
    "image.save(image_path)\n",
    "print(f\"✅ Image saved to {image_path}\")\n",
    "\n",
    "# ------------------------\n",
    "# STEP 2: IMAGE → VIDEO\n",
    "# ------------------------\n",
    "print(\"🎥 Generating video from image...\")\n",
    "pipe_vid = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-video-diffusion-img2vid\",\n",
    "    torch_dtype=torch.float32\n",
    ").to(\"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = pipe_vid(\n",
    "        image,\n",
    "        num_frames=num_frames,\n",
    "        num_inference_steps=num_inference_steps_vid\n",
    "    )\n",
    "\n",
    "imageio.mimwrite(video_path, result.frames, fps=8, quality=8)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"✅ Video saved to {video_path}\")\n",
    "print(f\"⏱️ Total generation time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# ------------------------\n",
    "# Display results in notebook\n",
    "# ------------------------\n",
    "display(Image.open(image_path))\n",
    "display(Video(video_path, embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88dca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ff07358e6e4395b28ceb155ac41948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Load model (example for Stable Diffusion)\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cpu\")  # or \"cpu\" if no GPU\n",
    "\n",
    "# Save locally (optional)\n",
    "pipe.save_pretrained(\"./models/stable-diffusion-v1-5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d7eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
